# CSAPP读书笔记01-计算机系统漫游


# 计算机系统漫游

*   如何避免由计算机表示数字的方式引起的奇怪的数字错误。
*   怎样通过一些小窍门来优化自己的C代码，以及充分利用现代处理器和存储器系统的设计
*   编译器是如何实现过程调用的，以及如何利用这些知识来避免缓冲区溢出错误带来的安全漏洞
*   如何识别和避免链接时那些错误
*   如何编写自己的Unix shell，以及自己的动态存储分配包，和自己的Web服务器
*   认识并发带来的希望与陷阱

本书将跟踪 helloworld 程序的生命周期来开始对系统的学习，从它被程序员创建开始，到在系统上运行，输出简单的消息，然后终止。

我们将沿着这个程序的生命周期，简要地介绍一些逐步出现的关键概念、专业术语和组成部分。

## 信息就是位+上下文

**源程序**（源文件）即程序员通过编辑器创建并保存的文本文件，文件名是 hello.c。源程序实际上就是一个由值 0 和值 1 组成的位序列（又称比特序列）。

> 8 个位被组织成一组，称为**字节**。每个字节表示程序中的某些文本字符。

> 大部分现代计算机系统都是用 ASCII 标准来表示文本字符，这种方式实际上就是用一个**唯一的**、**单字节大小的整数值**来表示每个字符。例如整数值 97 用于表示小写字母 a。

hello.c 程序是以字节序列的方式存储在文件中，每个字节都有一个整数值，对应于某些字符。

> 像 hello.c 这样只由 ASCII 字符构成的文件称为**文本文件**，所有其他文件都称为**二进制文件**。

系统中的所有信息，包括磁盘文件、内存中的程序、内存中存放的用户数据以及网络上传送的数据，都是由一串比特表示的。区分不同数据对象的唯一方式是我们读到这些数据对象时的上下文（环境）。

## 程序被其他程序翻译成不同格式

为了在系统上运行 hello.c 程序，每条 C 语句都必须被其他程序转化为一系列的低级**机器语言**指令。然后这些指令按照一种称为可执行目标程序的格式打好包，并以二进制磁盘文件的形式存放起来。

> 目标程序也称为可执行目标文件。

Unix 系统上，从源文件到目标文件的转化是由**编译器驱动程序**完成的：

```shell
gcc -o hello hello.c
```

在上面的命令中，GCC 编译器驱动程序读取源程序文件 hello.c，并把它翻译成一个可执行目标文件 hello。这个翻译过程可分为四个阶段完成：

执行这四个阶段的程序（预处理器、编译器、汇编器和链接器）一起构成了编译系统(compilation system)。

* 预处理阶段

  预处理器(cpp)根据以字符 # 开头的命令，修改原始的 C 程序。比如 hello.c 中第 1 行的 `# include <stdio.h>`命令告诉预处理器读取系统头文件 `stdio.h` 的内容，并把它直接插入程序文本中。结果就得到了另一个 C 程序，通长以 `.i` 作为文件名扩展。

* 编译阶段

  编译器(ccl)将文本文件 hello.i 翻译成文本文件 hello.s，它包含一个**汇编语言程序**。该程序包含函数 main 的定义，如下所示：

  ```c
  mian:
  	subq	$8, %rsp
  	movl	$.LCO, %edi
  	call	puts
  	movl	$0, %eax
  	addq	%8, %rsp
  	ret
  ```

  从第 2 行开始往下的每条语句都以一种文本格式描述了一条低级机器语言指令。

* 汇编阶段

  汇编器(as)将 hello.s 翻译成**机器语言指令**，把这些指令打包成一种叫做**可重定位目标程序**(relocatable object program)的格式，并将结果保存在目标文件 hello.o 中。hello.o 文件是一个二进制文件，它包含的 17 个字节是函数 main 的指令编码。如果我们在文本编辑器中打开 hello.o 文件，将看到一堆乱码。

* 链接阶段

  hello 程序调用了 printf 函数，它是每个 C 编译器都提供的标准 C 库中的一个函数。printf 函数存在于一个名为 printf.o 的单独的预编译好了的目标文件中，而这个文件必须以某种方式合并到我们的 hello.o 程序中。链接器(ld)就负责处理这种合并。结果就得到 hello 文件，它是一个**可执行目标文件**（或者简称为可执行文件），可以被加载到内存中，由系统执行。

## 了解编译系统如何工作是大有益处的

对于简单的程序，我们可以依靠编译系统生成正确有效的机器代码，但是在面对复杂程序时，了解编译系统是如何工作会给我们带来帮助，主要体现在：

1. 优化程序性能

   一个 switch 语句是否总是比一系列的 if-else 语句高效得多？

   一个函数调用的开销有多大？

   while 循环比 for 循环更有效吗？

   指针引用比数组索引更有效吗？

   为什么将循环求和的结果放到一个本地变量中，会比将其放到一个通过引用传递过来的参数中，运行起来快很多呢？

   为什么我们只是简单地重新排列一下算术表达式中的括号就能让函数运行得更快？

2. 理解链接时出现的错误

   链接器报告说它无法解析一个引用，这是什么意思？

   静态变量和全局变量的区别是什么？

   如果你在不同的 C 文件中定义了名字相同的两个全局变量会发生什么？

   静态库和动态库的区别是什么？

   我们在命令行上排列库的顺序有什么影响？

   为什么有些链接错误直到运行时才会出现？

3. 避免安全漏洞

   缓冲区溢出错误

## 处理器读并解释储存在内存中的指令

此刻，源程序已经被编译系统翻译成了可执行目标文件 hello，并被存放在磁盘上，若想要在 Unix 系统中运行该可执行文件，则需要将它的文件名输入到名为 shell 的应用程序中：

```shell
linux> ./hello
hello, world
linux>
```

在 Unix 系统中，shell 是一个命令行解释器，它输出一个提示符，等待输入一个命令行，然后执行这个命令。如果该命令行的第一个单词不是一个内置的 shell 命令，那么 shell 就会假设这是一个可执行文件的名字，它将加载并运行这个文件。所以在此例中，shell 将加载并运行 hello 程序，然后等待程序终止。hello 程序在屏幕上输出它的消息，然后终止。

### 系统硬件的组成

为了理解运行 hello 程序时发生了什么，我们需要了解一个典型系统的硬件知识。一个系统硬件包含以下几部分：

1. 总线

   **总线**负责在各个部件间传递信息。它通常被设计成传送定长的字节块，也就是**字**(word)。字中的字节数（即**字长**）是一个基本的系统参数，各个系统中都不尽相同。现在的大多数机器字长要么是 4 个字节（32位），要么是 8 个字节（64位）。

2. I/O设备

   I/O（输入/输出）设备是系统与外部世界的联系通道。每个 I/O 设备都通过一个**控制器**或**适配器**与 I/O 总线相连。控制器和适配器之间的区别主要在它们的封装方式。

   **控制器**是 I/O 设备本身或者系统的主印制电路板（主板）上的芯片组。
   **适配器**是一块插在主板插槽上的卡。

   它们的功能都是在 I/O 总线和 I/O 设备之间传递信息。

3. 主存

   主存是一个临时存储设备，在处理器执行程序时，用来存放程序和程序处理的数据。
   从**物理**上来说，主存是由一组动态随机存取存储器（DRAM）芯片组成的。
   从**逻辑**上来说，存储器是一个线性的字节数组，每个字节都有其唯一的地址（数组索引），这些地址是从零开始的。

4. 处理器

   中央处理单元（CPU）简称处理器，负责解释（或执行）存储在主存中指令的引擎。处理器的核心是一个大小为一个字的存储设备（或寄存器），称为程序计数器（PC）。在任何时刻，PC 都指向主存中的某条机器语言指令（即含有该条指令的地址）。从系统通电开始，直到系统断电，处理器一直在不断地执行 PC 指向的指令，再更新 PC，使其指向下一条指令。

   处理器看上去是它的**指令集架构**的简单实现。但是实际上现代处理器使用了非常复杂的机制来加速程序的执行。因此，本书将处理器的**指令集架构**和处理器的**微体系结构**区分开来。

   **指令集架构**描述的是每条机器代码指令的效果。

   **微体系结构**描述的是处理器实际上是如何实现的。

### 运行 hello 程序

当我们在键盘上输入字符串 `./hello` 后，shell 程序将字符逐一读入寄存器，然后再把它们放到内存中去。

当我们敲下回车键，shell 程序就知道我们已经结束了命令的输入。然后 shell 执行一系列指令来加载可执行的 hello 文件，这些指令将 hello 目标文件中的代码和数据从磁盘复制到主存（数据包括最终会被输出的字符串`hello, world\n`。

一旦目标文件 hello 中的代码和数据被加载到主存，处理器就开始执行 hello 程序的 main 程序中的机器语言指令。这些指令将 `hello, world\n` 字符串中的字节从主存复制到寄存器，再从寄存器复制到显示设备，最终显示在屏幕上。

## 高速缓存至关重要

这个简单的例子揭示了一个重要的问题，即系统花费了大量的时间，把信息从一个地方挪到另一个地方。hello 程序的机器指令最初是存放在磁盘上，当程序加载时，它们被复制到主存；当处理器运行程序时，指令又从主存复制到处理器。类似地，字符串 `hello, world\n` 开始时在磁盘上，然后被复制到主存，又被复制到寄存器，最后从寄存器复制到显示设备。

对于程序员来说，这些复制就是**开销**，减慢了程序真正的工作。因此，系统设计者的一个目标就是使这些复制操作尽可能快地完成。

根据机械原理，较大的存储设备要比较小的存储设备运行得慢，而快速设备的造价远高于同类的低速设备。

例如，寄存器只能存储几百字节的信息，而主存里可存放几十亿字节，但处理器从寄存器中读取数据比从主存中读取数据要快 100 倍。

近些年随着半导体技术的进步，这种差距还在持续增大。加快处理器的运行速度比加快主存的运行速度要容易和便宜得多。

针对这种处理器与主存之间的差异，系统设计者采用了更小更快的存储设备，称为**高速缓存存储器**（cache memory，简称为 cache 或高速缓存），作为暂时的集结区域，存放处理器近期可能会需要的信息。

Cache 也会分级，位于处理器芯片上的 L1 高速缓存的容量可以达到数万字节，访问速度几乎和访问寄存器一样快。L2 高速缓存的容量为数十万到数百万字节，它通过一条特殊的总线连接到处理器。进程访问 L2 高速缓存的时间要比访问 L1 高速缓存的时间长 5 倍，但是这仍然比访问主存的时间快 5~10 倍。

Cache 是用一种叫做静态随机访问存储器（SRAM）的硬件技术实现的。因为有了 Cache，系统可以获得一个很大的存储器，同时访问速度也很快，它利用了高速缓存的局部性原理，通过让 Cache 里存放可能经常访问的数据，大部分的内存操作都能在快速的 Cache 中完成。

> 局部性原理：即程序具有访问局部区域里的数据和代码的趋势。

意识到 Cache 的存在，让程序员能够利用 Cache 将程序的性能提高一个数量级。

## 操作系统管理硬件

当 shell 加载和运行 hello 程序时，以及 hello 程序输出自己的消息时，shell 和 hello 程序都没有直接访问键盘、显示器、磁盘或者主存。取而代之的是，它们依靠操作系统提供的服务。所有应用程序对硬件的操作尝试都必须通过操作系统。

操作系统有两个基本的功能：

1. 防止硬件被失控的应用程序滥用
2. 向应用程序提供简单一致的机制来控制复杂、不同的低级硬件设备。

操作系统通过几个基本的抽象概念（**进程**、**虚拟内存**和**文件**）来实现这两个功能。

### 进程

像 hello 这样的程序在现代系统上运行时，操作系统会提供一种假象，就好像系统上只有这个程序在运行。程序看上去是独占地使用处理器、主存和 I/O 设备。这种假象是通过*进程*这个概念来实现的。

进程是操作系统对一个正在运行的程序的一种抽象，在一个系统上可以同时运行多个进程，而每个进程都好像在独占地使用硬件。而**并发运行**，则是说<u>一个进程的指令和另一个进程的指令是交错执行的</u>。

传统 CPU 在一个时刻只能执行一个程序，而多核 CPU 能同时执行多个程序。无论是在单核还是多核系统中，CPU 看上去都像是在并发地执行多个进程，这是通过 CPU 在进程间切换来实现的。操作系统实现这种交错执行的机制称为**上下文切换**。

操作系统保持跟踪<u>进程运行所需的所有状态信息</u>。这种状态，也就是**上下文**。它包括许多信息，比如 PC 和 寄存器的当前值，以及主存的内容。在任何一个时刻，单处理器系统都只能执行一个进程的代码。当操作系统决定要把控制权从当前进程转移到某个新进程时，就会进行上下文切换，即保存当前进程的上下文、恢复新进程的上下文，然后将控制权传递到新进程，新进程就会从它上次停止的地方开始。

从一个进程到另一个进程的转换是由操作系统**内核**（kernel）管理的。内核是操作系统代码常驻内存的部分。当应用程序需要操作系统的某些操作时，比如读写文件，它就执行一条特殊的**系统调用**（system call）指令，将控制权传递给内核，然后内核执行被请求的操作，并返回应用程序。

> 注意，内核不是一个独立的进程。相反，它是系统管理全部进程所用代码和数据结构的集合。

### 线程

在现代系统中，一个进程实际上可以由多个称为**线程**的执行单元组成，每个线程都运行在进程的上下文中，并共享同样的代码和全局数据。

### 虚拟内存

虚拟内存是一个抽象概念，它为每个进程提供了一个假象，即每个进程都在独占地使用主存。每个进程看到的内存都是一致的，称为**虚拟地址空间**。在 Linux 中，地址空间最上面的区域是保留给操作系统中的代码和数据的，这对所有进程来说都是一样。地址空间的底部区域存放用户进程定义的代码和数据。

每个进程看到的虚拟地址空间由大量准确定义的区域构成，每个区域都有专门的功能。了解每一个区域是非常有益的，它们分别是：

- 程序代码和数据

  对所有的进程来说，代码是从同一固定地址开始，紧接着的是和 C 全局变量相对应的数据位置。代码和数据区是直接按照可执行目标文件的内容初始化的，在示例中就是可执行文件 hello。

- 堆

  代码和数据区后紧随着的是运行时**堆**。代码和数据区在进程一开始运行时就被指定了大小，与此不同，当调用像 malloc 和 free 这样的 C 标准库函数时，堆可以在运行时动态地扩展和收缩。

- 共享库

  大约在地址空间的中间部分是一块用来存放像 C 标准库和数学库这样的共享库的代码和数据的区域。共享库的概念非常强大，也相当难懂。

- 栈

  位于用户虚拟地址空间顶部的是**用户栈**，编译器用它来实现函数调用。和堆一样，用户栈在程序执行期间可以动态地扩展和收缩。特别地，每次我们调用一个函数时，栈就会增长；从一个函数返回时，栈就会收缩。

- 内核虚拟内存

  地址空间顶部的区域是为内核保留的。不允许应用程序读写这个区域的内容或者直接调用内核代码定义的函数。相反，它们必须调用内核来执行这些操作。

### 文件

**文件**就是字节序列，仅此而已。每个 I/O 设备，包括磁盘、键盘、显示器，甚至网络，都可以看成是文件。系统中的所有输入输出都是通过使用一小组称为 Unix I/O 的系统函数调用读写文件来实现的。

## 重要主题

### Amdahl 定律

该定律的主要思想是，当我们对系统的某个部分加速时，<u>其对系统整体性能的影响取决于该部分的重要性和加速程度</u>。若系统执行某应用程序需要时间为 $T_{old}$，假设系统某部分所需执行时间与该时间的比例为 $a$，而该部分性能提升比例为 $k$。即该部分初始所需时间为 $aT_{old}$，现在所需时间为$(aT_{old})/k$。因此，总的执行时间应为：

$$T_{new}=(1-a)T_{old}+(aT_{old})/k=T_{old}[(1-a)+a/k]$$

由此，可计算加速比$S=T_{old}/T_{new}$为：

$$S=\dfrac{1}{(1-a)+a/k}$$

它告诉我们，要想显著加速整个系统，必须提升全系统中相当大的部分的速度。

Amdahl 定律一个有趣的特殊情况是考虑 $k$ 趋向于 $\infin$ 时的效果。这就意味着，我们可以取系统的某一部分将其加速到一个点，在这个点上，这部分花费的时间可以忽略不计。于是我们得到：

$$S_\infin=\dfrac{1}{1-a}$$

Amdahl 定律描述了改善任何过程的一般原则。除了可以用在加速计算机系统方面之外，它还可以用在公司试图降低成本，或学生想要提高自己绩点平均值等方面。

### 并发和并行

**并发**（concurrency）是一个通用的概念，指一个同时具有多个活动的系统。**并行**（parallelism）指的是用并发来使一个系统运行得更快。并行可以在计算机系统的多个抽象层次上运用。

1. 线程级并发

   构建在进程这个抽象概念之上，我们能够设计出同时有多个程序执行的系统，这就导致了并发。使用线程，我们甚至能够在一个进程中执行多个控制流。自 1960 年代初期出现时间共享以来，计算机系统中就开始有了对并发执行的支持。传统意义上，这种并发执行只是**模拟**出来的，是通过使一台计算机在它正在执行的进程间快速切换来实现的。

   在以前，即使处理器必须在多个任务间切换，大多数实际的计算也都是由一个处理器来完成的。这种配置称为**单处理器系统**。从 1980 年代开始，在大规模的计算中，开始出现了多处理器系统的身影，它是<u>一个单操作系统内核控制的多处理器</u>组成的系统。

   多核处理器是将多个 CPU（称为【核】）集成到一个集成电路芯片上。典型的多核 CPU，每个核都有自己的 L1 和 L2 高速缓存，L1 高速缓存又可以分成两个部分，一个保存最近读取到的指令，另一个存放数据。酷睿 i7 可以让每个核执行两个线程，所以一个 4 核的系统实际上可以并行地执行 8 个线程。

   多处理器的使用可以从两个方面提高系统性能。首先，它减少了在执行多个任务时模拟并发的需要。其次，在执行单个大型应用程序时，他可以使应用程序运行得更快，当然，这必须要求程序是以多线程方式来书写的，这些线程可以并行地高效执行。

2. 指令级并行

   现代处理器可以同时执行多条指令的属性称为**指令级并行**。早期的微处理器，需要多个（3~10 个）时钟周期来执行一条指令。最近的处理器可以保存每个时钟周期执行 2~4 条指令。其实每条指令从开始到结束需要长得多的时间，大约 20 个或者更多周期，但是处理器使用了非常多的聪明技巧来同时处理多达 100 条指令。其中一个概念叫做流水线（pipelining），在流水线中，执行一条指令所需要的活动被划分成了不同的步骤，以此并行地执行多条指令，使处理器能够达到接近于一个时钟周期一条指令的执行速率。

   如果处理器可以达到比一个周期一条指令更快的执行速率，就称为**超标量**（super-scalar）处理器。大多数现代处理器都支持超标量操作。理解超标量处理器的高级模型，可以帮助我们理解程序的性能，然后，我们就可以写出拥有更高程度的指令级并行性的程序代码，因而也运行得更快。

3. 单指令、多数据并行

   在最低层次上，许多现代处理器拥有特殊的硬件，允许一条指令产生多个可以并行执行的操作，这种方式称为**单指令、多数据**，即 SIMD 并行。提供这些 SIMD 指令多是为了提高处理影像、声音和视频数据应用的执行速度。虽然有些编译器会试图从 C 程序中自动抽取 SIMD 并行性，但是更可靠的方法是用编译器支持的特殊的向量数据类型来写程序，比如 GCC 就支持向量数据类型。
